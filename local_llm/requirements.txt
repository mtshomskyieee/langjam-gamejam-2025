llama-cpp-python>=0.2.0
fastapi>=0.100.0
uvicorn>=0.20.0
pydantic>=2.0.0
requests>=2.28.0